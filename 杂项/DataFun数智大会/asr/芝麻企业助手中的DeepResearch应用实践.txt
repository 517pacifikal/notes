1: 在我这边做的一个项目叫芝麻企业助手中的这个 research 的一个应用实践。
1: 对，然后接下来会给大家展开介绍，谢谢。
1: 对，首先就是介绍一下我这分享的一个受众和目标，就首先大家可能需要对这个大模型 rap 和工程和 agent 有一定的这个了解，对，不然可能有一些技术会过得比较快。
1: 那么第二就是说，呃，希望大家对这个 c 语言技术本身是有一个理性的学习的一个了解过程，可能不是说认为它是一个万能的东西，你说大家接下来在业务中确实是会用到这块的技术。
1: 然后可能我讲的会比较落务实一些，对，然后接下来是说我们如何去迭代这个真正的生产场景的这个 c。
1: 对，首先是我们一个目录。
1: 对，然后第一部分呢，是给大家介绍，就是 deep research 的一个基本的定义，以及说它的一个基础实现是什么样子的。
1: 对，首先大家可以以一些问题来去开场，就是举例我们左边的这些问题，对吧？
1: 那大家会认为说，如果我们使用一个常用的 AI 助手的话，对，我们会如何的去解决这些问题啊？
1: 大家手上也有手机，可以现场搜一下，然后呃再以我当时测试的时候来来去看的效果，就是说你会发现，啊，你会发现说，如果我直接的用一个 AI 助手直接搜的话，那么大概率这些需要推理的一些问题，它是无法直接解决的。
1: 那这个时候，我们就会引升到说我有什么样的手段来去解决这些呃需要推理的，或者我没有提前在知识库或者训练到模型里面的问题。
1: 对，那由这个问题我们可以引发出来说，我们对问题的复杂度需要有一个科学的一个衡量标准。
1: 就第一档是我们在做这个显性的知识查询，那无论是说我们从模型里面训练进去知识，或者是说我通过 rap 对吧知识库直接去搜索，都是可以直接查到的。
1: 那第二档是这个隐性的知识查询，这对应的就是比如说，rag 间我需要通过跳跃多个文档去摘取相应的知识，然后来去解决我的问题。
1: 我第三个是有一个可解释的原理查询，就是我需要问我查询结果的为什么。
1: 那这个时候呢，模型就需要引入到推理，也就是说现在结合推理大模型的 RAG 等等方案来去做这个可解释性的一个呃输出。
1: 然后第四档就是假设我其实并没有提出一个直接的问题。
1: 但是我们又能从中推理出一些所谓的知识。
1: 呃，举个例子，比如说就像人一样，对吧？
1: 这个树从呃呃苹果从树上掉下来，然后我能推理出来万有引力定律，对吧？
1: 那这就是一个隐性知识查询的一个范围。
1: 那这呢，就是需要我们做叫 research 的这个方案。
1: 对，然后由此可见，呃，随着我们的推理能力要求变高，检索复杂度也变高，那在这个基础上面呢，我们需要用什么样的方案解决？
1: 这就是这一块是研究的范围。
1: 对，那首先就是说呃技术路径我们看一下，就是20~21年我们在做这个传统的 rapper 然后在22~23年我们引引进到这个 deep search 就是我使用更复杂的数据源和更深的这个呃 workflow 的处理电路来去解决问题。
1: 然后再到23年至今我们才发现说更复杂的任务需要用更呃复杂的一个动态的链路去处理，就是最底下的这个示意图就是加了反馈之后，模型能自行的去路由你的查询。
1: 那对应的这也会有一个特性的对比，就是首先是检索流程，那这 research 最大特点是因为它要呃理解的是未知的问题，所以它的动态，它它的检索流程必然是一个动态的，呃，其次就是在决策能力这里。
1: 呃，depresearch 它是不停的发现阶段性的目标，所以它需要有自主决策的能力。
1: 对，然后在交互模式上面，depresearch 会不停的希望说能得到新的知识，因为它的这个推理链是一个更长的一个推理链。
1: 在适用场景上面，呃，我们一般 deep research 只会用于复杂的这个任务，不然它的成本会非常高。
1: 嗯，然后核心组件上面，呃，deep research 的核心组件其实就是说我如何用这个多智能体和使用更多的一个工具，当然这两者本质上是为了扩充模型的上下文。
1: 嗯，然后在使用记忆和状态管理来去实现一个更长期的一个对话，去解决更复杂的问题。
1: 也有一些关键的技术点，这个我们后面会展开。
1: 对，然后这也有一个案例，就是说如果我把一个问题输入进来，对吧？
1: 那这个如果是 deep research 的话，它会首先有一个 planner 去呃规划说我应该把它拆解成一个什么样的分布的问题。
1: 然后再去分别调用的执行兴趣，分别搜，搜到之后呢，他去做一个汇总，我最后就能返回说你这个呃最合适的一个结果。
1: 啊，这当然是一个最小化的内容。
1: 对，然后最后做一个总结，就是首先优点是说呃它是一个基于大模型驱动的一个 a 点，它相比起巨沃 flow 驱动是有一个本质区别的。
1: 那它首先就是能搭上模型的快车，就是只要模型变强了，那我们的大呃 deep search 的系统也会增强。
1: 另外就是说它搜索内容随着这种动态的扩充的方式，它可以自行的去搜索更多的信息，所以说会比你人工定义会好一些。
1: 对，然后当然它也有一些局限啊，就首先是模型如果很弱，你就最好不要再用它。
1: 我其次就是这个 memory 如何管理，或者现在叫上下文工程，啊，再或者是时间消耗，你的 c 端用户会不会不耐烦，啊，或者是这个训练和优化，就是我们说奖励函数该怎么定义的问题。
1: 对，然后这边最左边的图呢，就是一个最经典的 deep research 的一个原理图，其实本质上就是他加入了一个反思，然后通过这个反馈来去迭代他的 plan 该如何给一个更好的 plan。
1: 然后再去最终解决他的更密，对更因的一个问题。
1: 然后在这边呢，其实首先他有大比例的技术要点和 rag 是重合的，比如说你首先你还是要做数据准备，并不能因为他是 deep research 你就不做了。
1: 然后其次就是你也要构建对应的索引的系统，对。
1: 然后接下来就是这个 query 增强，就是生成 plan 以及说最后的一个结果生成，这些也是还是要做的哈，并不会说因为它升级就不用。
1: 对，然后在知识库准备里面，呃，我这给的案例就是我们在这个芝麻企业助手里面做这个呃 paper search 的时候，其中我们要做这个政策信息，那政策信息我我们为什么要划到这么细呢？
1: 因为本质上就是垃圾进垃圾出，还是第一条原则，就是如果你输入的是垃圾，或者很粗糙的话，你用更复杂的系统，你的效果也未必就很好。
1: 所以说我们需要把这个信息做到一个足够细的力度，这样你才能有一个准备充分的知识库，然后在这个知识库基础上面呢，你需要首先去拆解你你的业务的知识的复杂性。
1: 就是不能有一些很黑洞的，只有你知道，或者说只是你们一个小圈子里的这种私有知识，你要把它映射到一个公有的知识，这样才能对应到大模型预训练的那个数据集上。
1: 对，然后其次就是呃如果说我们不把这个东西拆这么细的话，我们模型在这个推理上面可能会有很严重的幻觉，然后这也是大家在真正上生产最担心的一个问题。
1: 嗯。
1: 然后我的建议就是说我们应该把这个知识库准备的尽可能的细，嗯，这可以花50%以上的成本。
1: 对，然后其次就是这个知识库准备环节，呃，这其实就是会和 RAG 的基础知识会更加挂钩一些，其实你应该是每种数据你要选择一个对应合适的方式，呃，比如说动模态数据啊。
1: 代码数据或者常见的这个表格和复杂文档数据。
1: 你只有使用对应的这个合适的处理方式，你才能保证说你的索引系统是能有效运行的，然后你才能返回一个呃对你比较有良好效果的一个结果。
1: 然后在数据处理部分，呃，也有一些小建议，就是说首先就是我以这个最常见的数据举例哈，就是 check in 的话，呃，我们怎么样能让它做的更好，一个是把数据拆的尽可能小。
1: 然后另外就是在分块系统上面，你需要尽可能的保留它的上下文。
1: 对，这是这些技巧的本质上的原则，对，就是保留关键信息和这个 RY。
1: 对，然后对应的具体案例就是说，比如说你1.1的这个 check in 你看，大家看就是这张图，这张图想表达的就是说，如果你给一个很模糊的图然后你又想返回这个，就是告诉用户说你的图很模糊，需要重新上传的话，你首先你可以把整个图扔进去，对吧？然后你也可以把这
1: 个图拆成 n 块，就是用上一页说的这个图像的 check in 的方式去把它拆成 n 块，然后分别的去理解，这样你就可以每一每一行的去告诉用户它到底是哪里不 ok。
1: 对，然后到最后1.3的，你就可以定位出来说用户到底是呃就是增加了语义理解之后，你就可以告诉用户到底是哪里有问题，你只需要精准的补充那个地方。
1: 对，这就是一个演进过程。
1: 然后同样的在这个 expanding 和索引的时候也是有对应的一些操作的，就首先是我们的向量，因为它是语义的一个表示嘛，那我们如何去做这个最合适的语义表示，对吧？
1: 比如说我到底是做这个 query 和这个就是整个问答队的全索引呢？
1: 还是说我只对最后一层做索引，或者我是两边独立做这个隐埋顶，其实都是不一样的效果。
1: 那同样的，它的这个分别该用在什么位置，这是一个很关键的操作。
1: 对，然后再就是你的场景的检索，必然是有很强的业务属性的。
1: 那这个时候你怎么把你的业务重排，去设计到你的场景里面去，对，做成一个合适的缩影，这可能也是非常关键的。
1: 对，然后这举例的是比较基础的一些常见的处理方式。
1: 好，接下来就是近期大家很喜欢讨论的这个上下文工程了。
1: 那首先第一部分就是呃为什么会有上下文工程？
1: 本质上就是因为模型变成一个 agent 驱动的这个 research 之后，它的信息环境变复杂了，它不再是说啊我只是跟一个人交互，或者我只是检索我的那个很小的知识库。
1: 对，他变成了说他同时要拿着呃各种各样的数据源，然后来去分析说哪些数据是我要的，然后去求这个最高的这个信息增益。
1: 对，也就是说其实他是有一个数学建模的，就是怎么样叫一个最优的信息增益解，对。
1: 那其实我们其实目标就是在构建这么一个自由信息系统，然后具体的手段就包括这边这几种，呃，一种就是很常见的这个 rag 来去做这个长期记忆的一个支持。
1: 然后另外呢，就是在这个，因为 react 本身是个框架嘛，在这个框架上面，你如果要做 memory 的话，你还需要加上你的逻辑，就是来构建说你到底该是哪些作为一个天级别，哪些做小时级。
1: 对，什么样定义你的 session 的边界，都是在这个尝试记忆的这个范围内。
1: 然后再就是整合你的各种，比如说代码信息啊，或者是框架信息啊，或者各种 MCP 引入。
1: 对，你说你自己的这个 query 增强该增强成什么样的格式，啊，以及说你做 agent 的话，你 agent 之间的这个通信，啊，包括最后的结构分析组成和最后整个的这个 memory 里面的呃 prompt 如果过长。
1: 你该怎么样去压缩或者分层，这些都是在这个部分处理的。
1: 然后处理完之后呢，其实最后应该得到说一个标准的记忆单元，来去包含以下的四块内容，就是首先是这个语音内容，然后里面主要是分为这个文本的 embedding 或者是模型的那个 Laura 的这个层，对。
1: 那另外就是元数据，比如说你各种各样的这个代码或者是文档，或者是一些图像。
1: 对，然后另外一部分就是前面提到的问题改写。
1: 那首先第一部分是这个上下文的改写，对。
1: 那第二部分其实呃体现在说重排的时候，因为 racker。
1: 大家如果用过千问的这个，千问三个 recorder 的这个，我们会发现说 recorder 不同，其实你最后的效果是差异非常大的。
1: 因为你的距离的度量会直接影响到你最后给用户展示的最关键的那条到底是哪条。
1: 对，然后呢，在这呢，我们常用的方式就是我把这个业务中的呃 query 和 another 全都拿去给模型去学习，然后来去返回一个更加符合我业务上期望的一个效果。
1: 我这两部分，呃，以及说对应这边，呃，我们如果用配置的方式来去搞，就是说呃我应该是只用问题呢？
1: 还是用问题加上答案一起来去做返回？
1: 对，就说对应的一些设置，比如说我要多少条相关性。
1: 应该设到多少？
1: 这些都是常见的一些参数。
1: 对，然后还有一块就是刚才介绍的那个呃 embedding 的一个复杂的一个操作，首先你要根据你的数据类型做一个路由。
1: 对，然后路由完之后呢，再根据这个路由去，你才能将这个 query 转化为对应的合适的那个重写后的语句。
1: 比如说如果你是用来查向量库的，对吧？
1: 那你的文本你应该转化成有对应查向量库的这个语义。
1: 那同样你查关系库呢，又是另外一种语义。
1: 对，然后这些语义如何统一呢？
1: 就是说我们需要在最前面有一个元数据的一个管理。
1: 对，然后通过元数据来去填充说我这种每种 prompt 应该放一个什么样的东西。
1: 对，那对应的底下，如果说我们实际生产中经常遇到的，比如说加入 table 啊，或者说长文本，那我或者说多文档，我分别该去如何的去索引，来去构建这个系统，其实就是无非在原数据上面再加一个多层次的系统。
1: 然后接下来是这个 promote 工程的一个整体的一个呃就是关于 promote learning 能做的一个事情，就是首先你你的 event 应该有输出，然后你的输出呢应该是可以反馈的，就是量化的反馈。
1: 然后这个量化反馈又应该是可以迭代的。
1: 就是拆解成三步，然后通过这个 learning 的方式去让你的 prompt 重写器输出那个更优秀的 prompt 对，这是一个稍微高阶一些的操作，然后它是有一定的运行成本的，就是大家如果是在线使用的话。
1: 需要考虑一下它的一个成本。
2: 啊。
1: 我接下来还有另外一个操作就是如何规避这个上下玩窗口，就是最简单的办法就是我把这个搜索做两步，一步就是说我先把我的检索从静态改成动态。
1: 这也是目前这个 AI 写码工具里面，像 broad code 呀，或者 Openai 最新版本，对吧？
1: 他们其实做的这个事情，就是说不再去设一个静态的锁引器，而是每时每刻动态的去索引。
1: 那第二个事就是说我应该把知识注入到我的模型里面，把它变成一个参数化的记忆。
1: 那这这这一步就是可以规避我们上下文的一个长度。
1: 啊，然后通过这两种方式结合起来呢，一般来说你的上下文就能突破两个限制，一个就是过于长，另一个就是你的上下文的那个索引是静态的，导致它过时。
1: 对，然后接下来是这个关于这个评估这块的框架，就是这是我们现在会用到的这 research 的评估的一些指标，来去确保说最后 research 的那个结果是可以被量化，以及说可以变得更好的。
1: 对，然后这接下来是有两个框架，这是第一个，第一个是呃我们如何去衡量这个 deprecate 的事实性的部分。
1: 对，然后这是这个 robots 框架的一个大概的一个逻辑，就是呃这个框架大家也可以在网上搜到啊，我这只是一个实践。
1: 我首先就是说我把我的 query 塞进去之后呢，那它是在这个，这有一个评价的一个指标，然后下一页会有，然后在这个通过这个评价指标去通过这儿的一个衡量逻辑，比如说交叉验证啊。
1: 啊，这个 query 检索啊之类的方式去分别验证你的结果是不是是对的。
1: 对，然后通过这种方式来去返回一个结果。
1: 这儿这个例子就是想说，比如说我搜绿茶的健康益处是什么，然后首先我能检索到这些数据源，然后再通过这些数据源和模型的回复，来去做这个框架的评测。
1: 评测结果就是这样，比如说这个框架它会扔出来几个片段，然后来去分别和你的那个 query 去做一一对应，然后最终认为说呃哪里有问题，他就会打一个分。
1: 这种方式是能让你的框架迭代起来的一个最关键的一个东西。
1: 嗯，啊，然后这是 Robot 的一个评价的一些维度。
1: 对，然后根据这些维度大家可以发现，他过于关注的是答案的事实性的问题，但是他对另外的一些，比如说答案的呃优美程度啊，或者说答案的这个整体的结构化啊，这些其实是不够关注。
1: 嗯，对，所以说那就会反映说，如果说我通过这种方式比，可能我只能说每次测试题我都是分别互相之间比，但是我很难说呃能保持一个长线的一个评测。
1: 对，那长线评测怎么办呢？
1: 就是有下一个框架，叫 check list 对，然后这 check list 的方案就是说，他会把这个标准答案先拆成 n 个检查点，然后去反向的去给 LM 打分，然后来去再对 query 和 LM 来去做这个评测。
1: 这种方式就是相对而言，你这个大模型如果够稳定的话，你是能做一个比较长线的一个检测效果。
1: 对，这也是一个例子，对。
1: 就首先我可以看到呃这也是一个就是通用的知识的一个问题啊，然后需要有一定的推理，然后这会，模型会通过设计这个 checkpoint 去建一些检查点，然后这些检查点它分别会赋予一个分值。
1: 对，然后最后呢，就是对，最后我们就会得到说呃如果有这些分值和这些结果呢，它会有一个更加那个呃多维度的一个评测，虽然可能它打分上没那么直观，但是它好处是你可以用在更广。
1: 就比如说我前面两个数据集是完全不一样的领域，但是你可以有一个相对量化的一个更长线的衡量标准，然后来去提升你模型的一个通用能力。
1: that 然后这有个问题，就是首先你 check list 是不是跟你想检查的这个 diff research 的结果是一致的，对吧？
1: 如果不一致，那他在别的方向上面迭代，其实不是你想要的效果。
1: 第二点就是说呃过于主观的那种部分，比如说呃 a 和 b 谁写的作品这个更加优雅之类的。
1: 这种方案也还是不能很好的衡量。
1: 对，然后那呃继续往下做呢，其实就只有一个一个方向，就是投入成本，你做的更细。
1: 所以我强调说，如果投入成本过高，你得想一想你的业务主张到底是什么。
1: 对，我们是不是要做成那种成对，然后这也是一个，就是他大概的一个构建框架，对，就是对前面做一个更完整的展示。
1: 好，然后第二部分我可以就是介绍一下我们业务中具体怎么去用我们刚刚才介绍这个框架。
1: 嗯。
1: 首先是呃关于芝麻企业信用啊，芝麻企业信用的话，呃，首先蚂蚁集团的芝麻信用大家应该都是比较熟悉的，然后企业信用呢，就是呃它是其中面向企业主的那部分，就是类似一个企业主版本的芝麻信用。
1: 然后它解决的问题呢，就是全量的工商呃工商的这个主体，然后我们去为这些企业主提供一个企业维度的芝麻分，以及对应的金融和商业服务。
1: 我这个是需要，因为是有企业主身份的同学才能在支付宝里面看到，所以说可能大部分同学不太了解。
1: 嗯，然后在这个基础上面呢，我们目前做的这个企业助手就是面向企业主来去给他这个相应的提供智能化的，把这些服务自动化串联啊。
1: 以及深入分析他的企业和市场的一些情况啊，呃，对，然后比如说或者是在这个招标啊，这些特殊的领域去给他完成这个信息搜索和精准推荐，以及说精准分析的这些任务的这么一个工具。
1: 然后目前大概是有3,000万的一个用户量。
1: 对，然后这是一些具体的案例，比如说呃我我有用户需要搜这个标标讯，对吧？
1: 那对应的标讯里面，我们在市场上每天可能有呃每天目前应该是有50万的一个存量标讯，呃，这50万标讯里面，我要先找出来三条可能是最符合他当前这个公司情况的。
1: 然后并且他投的中标率高的，所以这是一个比较典型的 JAVE 测试任务。
1: 然后在这个基础上呢，我们还要对他做成这个，就是更深入的，就是帮他分析这个项目，他怎么样做可以中标的概率高。
1: 对，然后进行一些相应的这个数据和这个结果的一些呃就是 Deeper research 的研究。
1: 嗯。
1: 对，那在这个框架下面大家可以看到，就是呃要完成这个事情，我们一共做了这么多项的一个工作，就包括说我如何去做他的这个做这个深度的分析，就是 deprecate 的功能啊，你说根据用户调研去提升那个推荐啊。
1: 或者是加那个 UPS 去怎么对标到我们强化学习训练的目标，我最后完成一个整个的一个还算效果还算可行的一个版本。
1: 对，然后首先就是两个关键的一个大框架吧，第一块是这个 agent AI 的架构，就是我们一开始也是一个基于 workflow 的 deep search 的这么一个方案，然后在后面呢，就是发现用户。
1: 因为你给他一个搜索框，他会在里面问任何问题，所以说你用 workflow 是很难解决这么多用户的诉求的，所以我们把它升级到这个飞桨 AI 的一个框架，然后通过这些跟进通靠啊。
1: 提升这个 LM 的强化学习的这个呃 i o event 的能力啊，这些方式以及说把这个任务编排从以前的流水线方式改成一个智能的方式，然后去解决一些详细的问题。
1: 然后再往下的话是有一些具体的介绍，就是说首先第一部分是我们从算法角度来看，我们有哪些呃真实的落地挑战？
1: 那就包含说，首先知识更新你可能是滞后的，因为呃标训的话，它是每天是用户是希望分钟级别能拿到最新的，你不可能训练进去，对。
1: 那第二个就是上下文精准度不足。
1: 呃，这有几个原因啊，一个是说用户，大家其实发现用户其实很懒的，他可能就给你呃五个字不到，然后但是你要给他理解出来那么多的一个，他公司到底是干嘛，对吧？
1: 他想要一个什么标选，这其中的 gap 是非常大的。
1: 同样还有另外一个原因就是你上下文很容易输入过多，对，就是一般模型16K 的一个最优的上下文，我们随便一篇标讯就已经两三千字了，对吧你随便放3篇其实可能就超了。
1: 然后再就是关于复杂推理能力，如果使用传统 RAG 的话，它没办法去很好的去跨文档和跨领域的去分析，呃，比如说同时拿企业信息和标兵信息去做一个结合分析。
1: 然后最后就是整个的系统成本会非常大，就是我不觉得有什么公司能维护的了这么复杂的一个动态系统，所以说我们必须简化它的架构。
1: 那可能这边就是我们做的一些关键优化，这是也是算法角度的吧，这样。
1: 那这些我个人认为啊是老生常谈的一些东西。
1: 啊，所以说其实可能更关键的在于说，如果是生产环境，我们更多是解决这一方面的问题，会比前面那一页的内容会更加的多。
1: 那首先就是这个多步流程下，对吧？
1: 你的 agent 呃，AI 确实听起来很酷，但是你的多步流程下错误率上升很高。
1: 那其次就是你的 TOKEN 用量的成本。
1: 对，我不知道大家调用这个外部模型的感受怎么样啊，我们这来说是烧的钱是非常多的。
1: 那以及说最后的就是，如果你的公司已经很多年，你有一个非常庞大的传统的系统，对吧？
1: 你怎么样用 a 能 AI 来去驱动它，可能光接口适配你就要干很久。
1: 对，所以就是这三个问题呢，我们也做了一些量化的一个框架的建模，就首先呃我通过可靠性，对吧我会去算说我到多少步可能是我能能容错的一个上限，比如说我每一步我应该把错误率压缩到多少我才能保证我的步数的一个空间，对。那这我们可能
1: 做的三种方案，一种是这个通过人机协作的一些方式来去给用户一些操作空间。
1: 比如说我们做的一些阶段性的回滚，确保它不用全程任务全都重来。
1: 以及说做的一些独立的一些工作流来去呃缩短我的，尽可能缩短我的一个步数。
1: 另外就是关于成本上面呢，呃，首先如果你是平方层次的一个提升成本，或者说如果你的对话链路更长，你的成本就是三次方、四次方这样的，n 次方涨上去。
1: 那首先你怎么压呢？
1: 第一种方式就是你尽量很多输入，如果不是特别需要上下文，你就尽可能不要设计，你就把它给干掉。
1: 其次就是你的功能的工具，你必须要确保每个工具是聚焦的，就不要设计那种很通用的工具，很通用的工具会带来非常大的一个问题。
1: 对，接下来是关于这几个问题，据刚才介绍，框架我们是怎么解决的？
1: 对，首先第一部分就是说呃通过限定任务边界，就是刚说的聚焦，然后去明确说哪些是用户干，哪些是能干，然后功能，每个功能就是解决这个问题，我不会说奢望它能像 Manners 或者是什么通用 AI 一样解决所有领域问题。
1: 所以你说在某些关键节点，你还是需要和人协同的，所以这是现状，就很无感。
1: 嗯，然后另外就是说在这个操作上面呢。
1: 你需要怎么样去验证你的可，呃，怎么样验证你的操作是正确的，以及说你怎么样做及时恢复的。
1: 然后另外就是关于这个工程协同上面，怎么样去处理复杂的任务，把它拆解成简单的任务。
1: 对，那我们会发现说，可能大家经常看到一些很酷的 Demo 但其实你在生产上，你真正自己用，任何一家公司都给你提供不出来。
1: 本质上是在这一块的原因会多过于模型本身。
1: 那第二点就是在模型这边呢，我们会拆解我们的任务到底是一个多少分钟级的一个任务。
1: 目前理想的数值的话，呃，我可以再补充一下，就是目前理想我们认为是一个任务的时间控制在15分钟以内，是当前这个节点大模型的性能的最优的一个空间。
1: 有短了，你会浪费你的大模型算力，但长了的话，它失败率会暴增。
1: 嗯，然后在这基础上面，我们尽可能把我们的任务从这个小时级别拆分到 n 个这个分钟级的任务，然后再通过这些分钟级的任务再去拆解它的这个相应的操作，比如说你到底是哪些是通过强化学习解决。
1: 哪些是通过条件的解决，哪些是通过这个工具开发解决，然后再拆解成对应的更底层的一些子任务。
1: 而去把它变成一个分制的，可可可实现的一个事情。
1: 对，然后以及一个判断框架，就是说呃首先你的场景如果是，是不是非得用 a 跟它来去做，对，这是一定要考虑的。
1: 然后以及说现在能不能用，那这最关键的就是你的评测机。
1: 你的评测集设计的稍微不好，你会发现你得到的结果和你一开始预想的是天差地别的。
1: 然后呃但至于说，如果你评测集设计的好，你也想清楚这两个问题的时候。
1: 那如果你不可接受，我建议你就是先等一下。
1: 现在真的 a 跟的是一个很早期的一个方向，还不是说大家今天不做，明天不做，马上就会死，就会被别人干掉，其实不是。
1: 对，然后再就是关于这个 bad case 你需要如何拆解你的4类的 bad case 然后每一类分别你又要怎么识别？
1: 啊，然后这些 bad case 分别会带来什么问题？
1: 对，你就说你可能需要有一个电路来去处理你的 bad case 然后来去解决你的系统中的一些这种会影响到用户体验，或者让他流失的最关键的问题。
1: 对。
1: 然后在这基础上面呢，比如说像我们常遇到的，比如说首先 OTC 识别错，对吧？
1: 那你的数据直接就错了。
1: 那这里就是一些很苦力的一些活，就是你需要做一些更精准的雕花，或者限制你的 TOKEN 的一个数输出的三维，对。
1: 然后再像内容判决的话，你就需要去呃采用一些内容判决的工具去做检测，以及说呃对你历史的这个知识库做一些维护。
1: 然后再比如说是敏感内容，对吧？
1: 这个可能大家也都呃有见过，就比如说我们需要引入，及时引入这个政策关键词啊，做一些抽检啊。
1: 对，然后在这基础上面呢，就是你会发现，其实我们最关键的在于说，如何做到用户个性化的这个知识返回，以及效果不停的更好。
1: 就是说你需要有一个机制，就是在常见的检索到生成之间，你需要加加两个东西，一个是你要对用户的反馈有一个加权，这个加权必须得是模型可理解的加权。
1: 后来去返回给到模型，然后模型能根据这一个用户的个性化的偏好去给他返回个性化的内容。
1: 那这个加权怎么来呢？
1: 就是你需要构建你前面说的评估集嘛，评估集你需要构建为一个可存储的知识库。
1: 库，把这个知识库不停的迭代，这样你每一个用户的体验会越来越好，整体的 NPS 就会上升。
1: 对，因为我们目前发现就是没有任何一套标准的大模型系统能满足所有用户的问题，对。
1: 你你可能最关键的是你要给每个用户给他拆解开。
1: 对，然后这就是刚说的这个评测的一些维度，对吧？
1: 你该怎么样去拆你的评测，以及说加在什么位置，然后你的动态核心机制该做成一个什么样子，然后最后通过某公式去把它存储上去。
2: 对。
1: 然后接下来是知识库的部分，我们该怎么建？
1: 就是首先我们会发现说呃这个知识首先你得理解，那理解就会有 n 个操作，比如说呃关于垂直知识，对吧？
1: 你怎么样去能做到说比这个垂类服务做了十多年的垂类服务还要好，那这是一个可以用大模型很快提效的一个场景啊，对。
1: 那通过这个大模型提效呢，我们可以发现说你有这个，呃，可能我们我们自己实测吧，可能用了1/5的成本能追上别人这个花了10年的一个视频，这是呃很很棒的。
1: 然后在信息匹配这呢，我们会发现说因为现在大家会发现说，用户用搜索其实，尤其是在国外啊，其实很明确，已经很重的去改为使用 AI 助手，而不是再继续使用搜索了，那其实颠覆的就是这个匹配逻辑。
1: 那你如何使用，比如说 Geo 等方案，把这个你的这个信息扔到这个需要被搜的这些 AI 助手里面，这是一个关键点。
1: 我接下来就是在成本上面，我们因为现在我们把，我们都是分制的方法做数据任务，那你会拆出来 n 个子任务，子任务又有子任务，非常的重。
1: 对吧？
1: 那大模型的时候，我们如何把这些子任务设计成一套，这也是一个呃能拉开大家真正差距的关键点。
1: 然后其次就是说有很多新的一个数据，对吧？
1: 我们如何把这些新的数据引入？
1: 比如说现在其实是短视频时代，对吧？
1: 那我们如何把短视频数据能很好的结合在我前面的这些文版，或者是垂类的知识数据里面，这很关键。
1: 对，然后在这基础上面呢，就是呃拆解下来就是也是有三个事情，就是首先是你的信息理解力，你需要在，当然这是以招投标领域为例啊，在大家各自领域需要去各自分别去做一些拆解。
1: 然后以及你的处理效率。
1: 你的匹配效率，然后这三块是大模型可以做的。
1: 嗯，我在这基础上面呢，你会有一个架构，就是说，首先你的模型服务是，就是最底层的，你怎么样把前述的这些问题拆解为这个大模型能帮你快速解决的问题，然后在这基础上面再使用你的推理引擎和你的这个数据 play play 去。
1: 呃，最后得到你的更优秀的数据结果。
1: 对，然后最后你构建出来知识库，在我们这个场景啊，我们这个场景大概就是这个样子，就是首先你是文版 PDF 能够模态，呃，或者图像视频，然后在这基础上面，你会呃统一起来。
1: 把它们沉淀出来一套叫企业认知的东西和一套叫行业认知的东西。
1: 还有一套叫实时标讯的东西，哦，基于这三个东西呢，对，然后你就会能解决你上面的，可能是三五个核心的功能点，我每个功能点就是，还是前面强调的要聚焦，在这个层次上，还没有必要说把它发散到这个 Dapper research 里面。
1: 对，然后再在上面呢，就是在通过这个 A杠的框架去统一你下面的功能。
1: 啊，对，然后这是关于这个知识库，我们用的一些评价指标和这个知识库的迭代的一些方案。
1: 就上面是知识库的一些评价指标，然后中间的这个自动化呃质量监控和维护来去保证知识库的这个效果，然后最底下呢，就是在每个领域应该分别注意的点。
1: 这个是在我们这的一些特点。
1: 对，然后接下来是关于 a 本的层，就是我们会发现说，首先如果我们用传统方案的话，你的原数据到结果数据就是呃你的，或或者梅根的话说叫你的上下文到你的输出之间是有一个鸿沟的。
1: 然后另外就是你的传统工作组件上面也有一个鸿沟，然后在最后是，如果是人工来去负责流程的话，你的效率啊等等也会有鸿沟。
1: 那同样对于这边，就是首先你的上下文要做好一个新的管理，就是前面说的这个呃上下文工程的方式，去让模型能更好的直接面对原数据。
1: 比如说模型如何直接的去呃不再使用传统工作组件，而是通过 MCP 的方式去使用你的工作流，呃，以及说你的模型是否有一定的自我扣定的能力去创建你的这个所谓动态的链路，对。
1: 那这三个就是解决这边三个问题。
1: 那最后我们在解决这个问题的过程中使用的就是呃大家最近都说烂了的强化学习啊。
1: 对，然后呃首先强化学习你要做几个事情嘛，你要把工具作为你的反馈结果的话，你首先要把工具做标准化。
1: 那就包括这个翻成靠模式优化以及说你根据结果的可评估，对。
1: 那然后其次就是结构解偶，因为你得把这个，因为我们强化学习除了有结果监督，也有过程监督。
1: 对，那这个过程，每一步你必须解偶，你才能清晰的对它做监督。
1: 对，那同样的就是记忆增强的，就是说我们需要让模型的上下文变得更强，然后你强化学习返回的这个 plan 的空间才会变得更大，不然它 plan 就算是有你也是用不起来的。
1: 那最后就是这个整体的一个端到端的评测体系，你如何去呃验证说你强化学习的方向是和你业务目标是对的？
2: 嗯。
1: 我在这基础上面，我们能做的这个 deep research 框架就是这个样子的，就是首先在 planner 这呢，我们需要引入一个引入到一个执行器，然后执行器，我们需要把它拿到最后，调到工具的一个结果。
1: 再返回给这个 planner 然后这样 planner 就能对每一个工具的执行结果去做一个强化学习。
1: 对，然后在最后做一个统计来去呃加上它的上下文，有这三个数据之后，你就是有强化学习依赖的结果和过程，以及评价指标，然后最后返，加上返回的另外，你就可以把这个数据集给构建起来了，对。
1: 然后接下来就是在工具这块呢，你需要做的说，把你的工具拆清楚，这是我们在标讯领域拆的主要就是我们会把检索类的有五个，然后分别拆到一个非常精细的不同的数据集上。
1: 然后分析类的也会分别做，查数类的也会分别做。
1: 很忌讳的一点就是把这些工具混起来，混起来你基本就是不可学习的。
1: 嗯。
1: 对，然后通过这种方式，你最后得到的这个结果逻辑会很细，然后同时你才能实现前面这个执行器返回的结果能给那个 planner 做学习。
1: 对，然后这想强调的就是其实我们现在越来越从过程到结果，对。
1: 然后但是数据你其实是反过来的，数据你必须得是从只记结果到记录过程。
1: 对，因为只有这样呢，你才能，就是在这个案例下面，对吧？
1: 你才能更精细的让你的模型有更丰富的上下文来去决策说我下一个最优的动作是什么。
1: 如果没有这个东西，强化学习就是属于那个镜中月吧，水中花。
1: 然后在这基础上面，我们这发现一个特点，就是你需要特别注重这个持续的，这个完整的信息存储，对，因为时间是我们现在会发现你唯一不可改变的一个维度。
1: 对，然后那这就是一个案例，就是我们跑完的效果，就是呃你根据这个同样的两条这个分析公告，然后左边的呢是你通过这个 deep researcher 的方案，然后右边的呢就是如果我做这个 workflow 对吧？
1: workflow 的一个效果。
1: 对，然后但我们会发现说这个 research 它是能更加更好的学会一个分析的，对。
1: 呃，这个案例我在这就是没有那么多，然后后面就是但这张图呃这张图其实可能它长这个样子不是那么重要啊，对，我得强调一下，这张图长这个样子，本质上重要的是说这张图的是学习出来的。
1: 也是我今天想说的一个核心的重点，就是虽然我们一直在说 deep research 但其实你最后真正上线的时候，你沉淀下来的是我们 flow。
1: 对，他只是说这个 workflow 从以前人工定义出来的，变成你从你用 l 来去学习出来的一个最优的 workflow 对，这才是一个成本最低或者可行的上线方式。
1: 没有人会把这个线上面跑一堆的这个动态的一个一个的，对，这个我觉得现在是没有公司会这么干。
1: 对，那第四部分就是到我的这个呃讲话的一个部分。
1: 嗯。
1: 首先第一部分是呃大体的一个趋势展望吧，就是呃当然这个这个趋势不是特别长啊，只是一个非常短中期的一个展望。
1: 呃，首先就是我们会发现说呃包括这个 Openai 最近也开源了，不是，也没有开源但发布了它的一个的产品，我们会发现它并没有用它做 deep research 时候用的那套呃就是纯呃大模型驱动的一个，它是也做成了一个 workflow。
1: 本质上为什么呢？
1: 因为他发现这样做的性价比最高，对，而不是说是效果一定最好。
1: 对，效果可能就是因为效果一般，所以大家对他比较失望了。
1: 但其实这也是他能规模化服务的原因。
1: 那第二个点呢，就是这个所谓的程序性索引，程序性索引呃大家可以类比成动态索引，就是说我们现在越来越不建议说我们提前把这个数据和知识做一个静态的索引，而是应该让模型在这个呃得到上下文的时候，实时的去更新这个索引。这也是在我个人
1: 看来，目前这个上下文工程的一个核心。
1: 嗯，对，这两点是我认为是现在呃短中期的一个趋势，然后第三点就是 SDK 呢，虽然说这是一个很老牌的技术啊，但是我们会发现如果我们想对模型做插拔的这个插件的话。
1: 它还是一个性价比最好的一个方案。
1: 对，虽然它投入相比上述会高一些啊，但是它性价比确实还可以。
1: 那以及说再往后的 RST 这种我们一般是用在这个非常兜底的时候，可能才会这么用。
1: 对，一般时候你用 RST 会非常的重。
1: 嗯。
1: 那最后就是其实大家在做的是说，这些单点技术已经发明出来一段时间了，我们正在做的其实就是怎么样组装这些技术，形成一个最优的工程工程效果。
1: 嗯。
1: 对，所以我建议就是说大家根据自己组织和资源的一个情况来去呃实现自己的一个最最优的一个嗯选择。
1: 对。
1: 同样的说，呃，首先是大型呢，我建议是采用一个多技术融合，因为你的人力的这个技能站也比较全，你的知识也比较复杂，业务也复杂。
1: 你是更适合去做这个综合的，然后中小的话，我个人建议，如果不是特别重的需求，其实基于 RAG 或者是这个，就是动态索引，其实已经能解决大部分的问题了。
1: 对，其实 Openai 也是这么干的，对吧？
1: 那同样的就是在应用领域的话，就是也要看你到底是直接 ToC 对客的，还是说你只是说，比如说内部的一些专业场景用，或者说你现在其实是在做这个原型。
1: 对，这这三种需求是完全不一样的，那适用的这个技术也是完全不一样的。
1: 对，接下来是商业上面吧，就是首先，现在 this research 的技术方案，呃，在商业商业上，变现上其实路径还是这些，就是要么就是提供 SARS 服务。
1: 要么就是直接给公司做部署，要么就是这个垂直的一些应用，并没有什么特别新的啊，对。
1: 哦，当然也有一些是搞插件嘛，就是比如说像是李牧老师搞的国森数据啊，呃，或者是那个呃 Openai 前 CTO 搞的，对吧？
1: 其实他们是在做这个事情。
1: 那在这个 AI 搜索与深度研究上面，其实现在真正核心的点还是这几点，就是你要么替代的是 AI 搜索，对你要么就是解决以前这个，检呃搜图啊或者搜视频的一些能力，让它变得效率更高。
1: 对，要么就是分析一些文献，比如说 AI phone service 对，或者是一些呃跨行业跨语言的一些应用。
1: 然后这边就是有个成本计算啊，就是说建议大家用的之前一定要先算成本，不然你会发现，因为如如前面的一张图，对吧我们的成本是 n 次方上升的。
1: 对，然后你会发现，你为了填补业务的需要，你每多加一个节点，你的成本其实是加 n 次方的，对。
1: 另外就是在这个基础上面，有一些有一些业界的案例吧。
1: 对，首先就是在成本维度，对吧业界大概是一个什么样的价格，以及说消耗和这个市场的投入主要在哪？
1: 其次就是在商业化路径上面，如果是这个走 rap 路线的话，我们会发现其实已经有几家做的不错的，不管是这个通用搜索，还是这个垂直领域。
1: 对，当然这是在北京啊，对，国内的话大家还是得看一下市场情况。
1: 那同样的在这个最后，就是说我们会发现呃 that that research 现在也在从这个值返回结果转为转向执行，比如说帮你直接买单，对吧？
1: 或者是帮你直接去完成某个专业领域的任务，这个是我们正在做的，就是把这个用户一长串的操作电路给自动化。
1: 啊，这是我们下一步在做的事情，也就说我们会发现目前这个 AI 领域应用确实绝大多数还是在企业级 AI 上面。
1: 虽然说这个 Openai 的用户量已经20亿了，但确实是收费大头还是在企业级。
1: 对，这是我今天的一个分享的全部内容。嗯，谢谢大家。
