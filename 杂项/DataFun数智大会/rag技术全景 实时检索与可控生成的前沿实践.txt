1: 模式是完全串联的，而且它的检索仅发生了一次。
1: 啊，这样的一个一次性检索加静态拼接的范式呢，它可能会导致一些问题。
1: 首先呢，就是单轮检索的信息固化，这什么意思呢？
1: 就是呃大模型它的生成，它只有一个依据，就是基于用户初始查询执行的一次性检索的内容，然后它的后续的生成就就完全依赖了这批固定的知识，他就没有办法根据他的生成内容发现自己呃有什么新的呃检索目标来发起新的检索。
1: 呃，这是第一个问题，然后第二个问题就是啊他的查询不准确会导致一些信息遗漏，因为哦因为结个 RG 流程，它的呃用户的，呃，它的整个 query 是用户设置的初始查询，但是用户他在呃呃发起任务之前。
1: 他可能并不能准确的知道我整个任务，我如何生成我的检索词。
1: 才可以导，呃，才可以生成，呃，才可以检索出呃帮助我下游任务，可以准确生成回答的内容。
1: 所以说用户初始的检索语句不精准，它就可能会导致我在后续呃生成的时候，我需要的一些关键知识，导致了它的遗漏。
1: 然后最后就是错误累积效应，就比如说呃我们在生成的上游阶段我们引用了一些不准确甚至错误的信息，但是大模型它在后续生成过程中，它是没有办法发起二次的检索补救的。
1: 它的后续只能根据它呃是呃上游上游传递给他的一些错误的上下文，继续生成内容，这样的话呢，就会导致幻觉问题。
1: 所以这就是为什么我们需要一个动态检索的机制。
1: 啊，它的一个核心的目标就是呃希望大模型它可以在一边生成他的内容的时候，然后呃通过他自己呃对目前生成内容的一个判断，然后发起二二轮乃至多轮的检索，然后从而提升他生成内容的可信度。
1: 那么问题就来了，就是我们在，我们希望大模型在自己生成感觉到不确定的时候，它去发起检索。
1: 那大模型什么时候它知道自己对于自己生成的内容感觉到不确定呢？
1: 这就是呃检索触，呃检索触发，呃这就是动态检索机制的一个核心策略，就是他什么时候判断自己需要触发解锁？
1: 呃，目前比较 Sota 的一个做法就是呃我们可以利用呃一些预训练大模型的一些固有的输出值，比如说生成概率或者是自自注意力权重，我们来作作为一个检索触发的条件。
1: 然后呢，我们可能会预设一个呃阈值和呃这些固有的输出值进行比较，呃，如果它低于了我我们预设的一个阈值，我们就可能会认为大模型在这个地方对于呃生成的 TOKEN 内容觉得不确定了。
1: 这这个时候我们就会触发检索补充知识。
1: 接下来呢，我会用两个论文里的代表性框架，来给大家直观的感受一下呃这个动动态出发检索机制是如何工作的。
1: 呃，首先是第一个呃论文，dragging。
1: 它是由两个关键的组件组成的，首先是 writer 它就是呃我之前介绍到的，它是呃一个决定何时动态触发检索的一个组件。
1: 然后下一个模块就是 QFS。
1: 他他的工作就是呃在我触发了检索之后，我如何构造一个检索词，去触发这个呃去去输入进检索器，去呃检索到和当前相关的一个文本片段，然后呃我们首先先看一下 QFS 它是如何工作的。
1: 呃，这里有一个示例。
1: 当检索触发的时候呢，呃，他可能呃当检索触发的时候，就比如说呃呃模型在生成到呃乔布斯创业经历的一个一段文本。
1: 生成到他退学后这个文本的时候，他呃他不太确定下下文如何补充细节，然后这个时候会触发检索，然后 QFS 他在这个时候呢，他就会构造这个检索。
1: 它是怎么构造的呢？
1: 它会计算对当前这个 TOKEN 退学后这个 TOKEN 呃，它会判断和它前文的所有 TOKEN 之间的自注意力权重，然后呢，对这些自注意力权重进行一个计算和排序，然后筛选出和退学后最相关的关键词。
1: 然后通过前文的原始顺序，然后进行拼接，然后生成这个呃查询文本。
1: 然后这个是呃 Dragon 的另一个模块，就是实时信息需求检测模块。
1: 它的主要工作就是呃它它是来判断，呃，它是通过一些算法来计算什么时候大模型需要去触发检索，从外部知识。
1: 然后它它的计算呢，它是由三个维度来决定的。
1: 呃，我们可以看到这三个 step 呃，首先呢是生成的不确定性，呃，这个呢就是模型对于当下输出 TOKEN 的一个概率，它可能呃反映了它对当下生成 TOKEN 的一个呃置信度，一个确信的程度。
1: 然后呢第二步就是自注意力权重，呃，这个呢可能就是反映了呃对当前 TOKEN 和已生成的所有上下文 TOKEN 之间的一个关注程度，就如果你的自注意力权重越高的话，就可能越说明当前当下的这个 TOKEN 它是一个有意义的关键字。
1: 然后第三步呢，它可能跟第二步是呃比较一致的。
1: 呃。
1: 也就是说在 red 工作之前呢，呃，我们会维护一个停用词表，然后呢我们会呃将当前的 TOKEN 还有所有高自注意力权重的 TOKEN 和这个停用词表进行比较，然后判断它是否是一个语义的关键词。
1: 如果是停用词的话，呃，就把它置0，如果否则的话置置为一。
1: 然后最后呢，我们会把三步计算出来的得分相乘，得到一个综合的分数，我们叫 s round 然后这里有一个示例呃给大家展示了一下，呃，这个 round 是如何工作的。
1: 就比如说呃我们我们在模型生成到上海东方体育中心是该市重要场馆，可容纳座位数为一。
1: 首先呢，呃，这个 Ryan 它会在生成每个 TOKEN 的时候，都对每个 TOKEN 进行一个置信度的评估。
1: 呃，当模型生成一这个数字的时候，呃，它会经过就是我之前介绍的三步来计算它的一个 rain 得分，它是如何计算的呢？
1: 就比如说生成数字一的时候，它发现它的概率极低，呃，0.0.005然后呢，呃，下一步就是检查它的自注意力权重，就是它在生成一的时候，它对它的前文的呃前文的哪些投肯他的注意力权重高。
1: 呃，然后找出他的自注意力权重值，然后选取其中的最大值，呃，作为另一个维度的得分，然后下一步就是语意重要性。
1: 语义重要性就是和停用词表进行比较，然后呃检查自身这个座位数一这个 TOKEN 和前文的所有高注意力 TOKEN 是否为停用词。
1: 如果不是提供词的话，就说明它是一个比较重要的 TOKEN 所以它的语意重要性的得分就为一。
1: 然后最后呢，它会得到一个综合的得分，也就是说把前三步的得分进行相乘，然后和我们预设的一个阈值进行比较，然后发现它高于阈值，就说明呃可能在模型在生成的这一个步骤的时候。
1: 它对它生成的内容不确定，然后此时就触发检索。
1: 然后在触发检索之后呢，呃，就由 QFS 它来构造查询，它把呃前文的自注意力权重高的关键词进行拼接，然后发起检索，然后检索到的关键词呢，呃呃，检索到的文本块呢，我们会在呃大模型生成截断的地方。
1: 我们补充进去，然后然后最终呢，使大模型可以纠正它生成的幻觉内容，然后呃根据他检索到的知识，补充真实的数据。
1: 然后下一个呃动态检索的代表性框架，它其实和呃 dragan 非常的类似。
1: 呃，它唯一呃不同的是，它的对于呃置信度的检测呢，它只有一个标准，那就是生成下一个 TOKEN 的概率。
1: 然后呃这里有一个示例呃展示了它的过程。
1: 呃，还有一点就是呃 flair 它可能它在生成呃句子的时候，它首先会预生成一段句子。
1: 然后呢，对预生成的这个这个句子里的每个 TOKEN 都做一个置信度的计算，也就是它的呃 TOKEN 概率的计算。
1: 然后发现预生成的句子里有某些 TOKEN 它的呃概率低于了我们预设的一个阈值，我们就会触发检索。
1: 然后此时呢，我们会把低质性的 TOKEN 通过一些掩码的方式把它掩盖掉，然后把整个预生成的句子作为一个检索词，去触发检索。
1: 在我们了解了如何使用实时检索，让大模型呃实时的动态的补充知识之后呢，我们进入下一个话题，就是可控生成。
1: 可控生成它的一个核心的呃一个核心的概念就是我们在呃我们在给定了大模型一个呃检索的知识之后，我们如何确保大模型它的生成内容是完全呃依托或者是锚定在我们这个检索的范围内的。
1: 我们首先现在来看一下，如果我们没有用到呃可控生成可能会有什么样的风险？
1: 呃，可能会有人有疑问说，呃，我们既然都已经使用了 Rag 我们都把呃检索的知识通过提示词的方式已经补充给了大模型，这样的话大模型总该按照我们呃提供的事实来生成回答吧。
1: 但是呢，其实呃事实不是那么简单，呃，就如果我们不在呃大模型的，比如说概率分布层或者解码策略里，我们让它显示的偏向我们的检索内容，很有可能大模型仍然会绕过我们提供的检索信息，去生成呃不符合事实的回答，也会产生幻觉。所以说这个
1: 就需要用到我们的可控生成的机制，它的一个嗯核心的目标就是哦我们如何在大模型的生成阶段，我们对它施加一个约束，然后让它的生成结果始终锚定到我们呃我们给它提供的检索知识里。
1: 然后呃这个思路呢，它有两个解决策略，一个是架构层面，一个是解码层面。
1: 然后我会通过两个代表性的框架，一个一个给大家呃看一下他们的工作流程。
1: 首先呢，在高层次上，架构层面，呃，我们可能会将呃我们的检索文档，把它抽象成一个 TOKEN 的 representation 然后经参与整个 transformer 的隐藏层的计算。
1: 然后呃通过这样的一个架构的呃改变呢，可以让呃就是模型的某个隐藏状态同时参考了当前的上下文和它的检索知识。
1: 然后另一个是解解码层面，就是我们可能会提前维护一个呃知识图谱或者是一些硬性的词汇表，然后我们呃强制让模型在解码的时候参考这些图谱的路径或者是词汇表。
1: 这样的话呢，才能保证它生成的内容可以在我们给定的合法边界里。
1: 我们首先先来看一下呃第一个可控生成的代表性框架，然后这个是 Retro 啊，它是如何实现让生成的内容显示的偏向这些检索知识的呢？
1: 它是呃通过修改我们标准的 Transformer 架构，它在标准 Transformer 架构的特定层，就比如说每三层中的一层，它插插入了一个知识增增强或者叫检索增强的模块。
1: 在论文里叫它 retro 块，但它实际上是一个 cross attention 块。
1: 它是通过呃分块的交叉注意力，将检索知识和上下文表示深入的整合。
1: 然后这里有一个流程可以给大家呃直观的看一下它是怎么工作的。
1: 呃，首先呢，第一第一阶段的自注意力层，它其实是和标准的 Transformer 是完全类似的，呃，模型会基于已经生成的上下文做一个 self attention 的计算，然后得到一个隐藏状态。
1: 然后接下来呢，就是呃我们就需要补充一些检索的知识，我们将我们召回的 top k 的呃检索的文档块，我们先将它经编码器编码，把它编码成一个知识的向量级。
1: 然后下一步就是呃 Retro 模块最关键的一步就是跨注意力融合，它是通过一个分块的交叉注意力，将当前存有当前上下文知识的一个隐藏状态，和我们补充的检索知识的知识向量进入。
1: 进行一个深入的融合。
1: 呃，进，呃，经经过交叉，呃，分块交叉注意力计算，我们得到一个知识增强的隐藏状态。
1: 然后它最终的呃概率分布计算呢，会基于我们最终这个经过知识增强的一个隐藏状态，计算呃所有 TOKEN 的一个概率分布。
1: 呃，我们这样的话呢，它就会使输出的分布偏向我们给定的一个检索知识。
1: 所以说，呃，return 呢，在解码的时候，将呃检索的知识知识通过知识向量的方式注入到整个 Transformer 的一个解码过程里。
1: 它会间接的改变呃它的呃所有 TOKEN 的呃概率分布，然后这样的话呢，呃，可以使生成的内，生成的内容更加依赖的检索知识。
1: 然后呃这个是可供生成的另一个代表性框架，呃，这个是 GCR 它可能依赖的知识组织形式不是文本块，而是知识图谱。
1: 呃，GCR 的工作流程是他是呃他呃他是如何实现生成偏向呃检索知识的呢？
1: 他是通过改造呃他的解码流程，呃，而不是架构。
1: 它是使生成的时候，呃，让它的解码强制的偏向检索到知识，它如何实现的呢？
1: 呃，首先呢，它会将知识图谱的所有的合法路径，把它预编译为一个前缀树。
1: 然后呢，在解码的时候通过一个硬约束，然后约束呃每一步的输出都沿着图谱的合法路线进行。
1: 然后这可能比较抽象，我们可以通过一个示例来看一下是如何工作的。
1: 首先呢，哦，在我们构建好一个知识图谱之后，我们会把知识图谱的所有的一个合法的推理路径，就是实体到关系到实体的一个推理路径，我们先把它格式化成一串串的 TOKEN 序列。
1: 然后呢呃这些 TOKEN 序列我们再把它插入到一个前缀中，然后呃前缀数中，然后这样的话呢，就呃每个前缀数呢，每个节点中，它都会有一个合法的后继 TOKEN 结合的集合。
1: 然后呃下一步就是图约束解码，在我们有了一个前缀数之后，我们如何约束呃大模型在我们给定的一个呃知识图谱的结构下进行解码呢，就是在解码的时候，模型可能会呃先将已经生成的一个 TOKEN 的序列当做前缀。
1: 我们先在前缀树中定位到某个某个节点，然后得出它的一个合法的后继的 TOKEN 集合。
1: 在我们有了一个合法的后继 TOKEN 集合之后，我们用呃 Logic process 将显示不存在我，呃，不在我们合，呃，合法的后继特后继 TOKEN 里。
1: 的所有的 TOKEN 概率把它置为负无穷，然后通通过这样的一个应约数的过程呢，我们确保了每一步的输出，它可以必然的映射到知识图谱里的呃真实存在的关系路径。
1: 然后呃下一个话题是联合训练。
1: 呃。
1: 我们目前的传统的 RAG 它的检索器和生成器看似是呃放在一个框架里一起工作的，但是实际上它们的呃训练是割裂的，它们的训练目标是不一致的。
1: 这就会导致一个异步训练的失配问题。
1: 什么意思呢？
1: 就是呃首先，检索器它是以检索的准确率或者说是召回率作为目标。
1: 但是呢，它没有办法衡量我检索出来的内容，对于我最终下一个生成质量的一个回答，是做了多大贡献的。
1: 也就是说检索器它只学会了一个关键词匹配，或者是近义词匹配，但是它没有学习到我检索到哪些知识可以让我的下一个生成器生成的更好。
1: 然后另一个就是呃因为整个流程从检索到生成的这个阶段，它是串联的，而且是单向的，所以说生成器呢，它只能被动的接受检索的结果，他没有办法说根据下游任务的反馈。
1: 就比如说呃他比呃他通过呃交叉熵比较了自己生成的答案和呃和 ground truth 之间的呃一个损失，可以把他这个损失反向的传传播给检索器，以持续优化检索的参数。
1: 然后这样的义务训练模式就会导致我的检索效果实际上跟我的生成的质量是脱节的。
1: 也就是说我在下游任务中很难实现的是检索和生成同时达到一个最优的效果。
1: 所以说这就需要我们的联合训练。
1: 联合训练它的一个呃核心思路就是我让解码器和生成器，我共享同一个损失函数，就比如说呃不同的下游任务，它有不同的得分。
1: 呃，但对于最通常的一个生成任务来说，可能就是我的生成的呃准确率或者是我的流畅度。
1: 然后我的下游的任务的损失呢，呃，我通过一些方法让它反向的传播给检索器的参数，然后让检索器的参数可以经，呃，可以通过下游任务的表现来呃实现优化。
1: 从而实现两个模块一致对齐。
1: 然后这样的一个流程，它既支持预训练，也支持微调，这是根据不同的呃任务需求决定的。
1: 然后我们就来看一下呃联合训练它是如何工作的。
1: 呃，其实呃整个 RAD 的呃全向传播这个流程大家应该很清楚，呃，主要呃主要的问题就是这个梯度它是如何从生成器，我再回传给我的检索器。
1: 然后这个这这个这里比较关键的一个呃一个变量，就可能是这个检索器输出的一个相似性得分。
1: 我们也知道大部分的检索器它做检索的时候，它可能做的是一个呃求点积的操作，它将文档向量和 query 向量呃经过一个点击，我得到一个相似性得分，然后并对这个文档进行排序。
1: 但这个相似性分数、文档向量和 query 向量，它就是呃整个检索器的可微分的部分。
1: 然后在我们的生成器有了一个梯度之后呢，我们就可以沿着这个相似性得分呃更新，反向传播，然后更新更新这几个参数，相似性分数，然后反向，呃，可以通过这个这个梯度就可以通过相似性分数反向的传播到文档向量和 query 向量中。
1: 在我们了解了整个联合训练的梯度是如何传播之后，呃，我们就来看一下联合训练的损失大，呃，大概是怎么计算的？
1: 然后这就涉及到了一个联合训练的代表性框架 Lass 呃，这个是论文里定义的一个损失函数。
1: 它是由几个部分组成的，一个是对齐损失梯度，对齐损失梯度呢，可能主要优化的是检索器参数，然后还有一个就是交叉熵的梯度，它就是我们比较常用的一个监督信号，是用来调整生成器的。
1: 我们可以一个一个的呃过一下，呃，首先是交叉熵，它就是我们最常见的深层次的一个损失函数，啊，它就是通过比较深层次的输出和我的一个真实值的差异，我们得到一个呃交叉熵的梯度。
1: 然后呃，接下来的三个呢，可能就是和我们的呃优化检索器比较相关的三个呃损失函数。
1: 呃，首先是注意力精蒸馏，它会首先呃注意力蒸馏是什么意思呢？
1: 它会首先看一下呃生成器，它在计算他在计算不同文档的 cross attention 的时候，他对不同的文档有一个呃不同的注意力权重。
1: 他通过检查呃生成器对这些文档的注意力权重和检索器他输出的一个相关分数相关性分数是否是对齐的，得出一个梯度。
1: 也就是说，它通过这样的一个计算呃限制了，就是如果生成器它在生成答案的时候，它重点参呃参考了某些检索文档，那么检索器它在检索的时候，也应该给这些文档一个比较高的相似性分数。
1: 所以这是注意力蒸馏，然后自然蒸馏呢，就是他对每一篇文档呃单独的计算，使用该文档，就单独使用该文档生成答案的一个自然分布。
1: 也就是说，如果某篇文档它单独存在的时候，生成器它就可以生成很好的答案，那么检索器就应该给它更高的相似性得分。
1: 然后下一个梯度是留一法，就相当于每个呃每篇文档它逐一的移除，然后我会评价一下它呃移除前和移除之后的生成答案的质量变化。
1: 如果移除某篇文档之后，生成的答案变，呃，就是变好或者变差，就可以反映这个文档是重要还是不重要。
1: 这样的话呢，也可以间接的影响呃检索器对当前文档的一个相似度的判断。
1: 接下来呢，我将通过几个案例呃给大家直观的看一下呃这几个 SOTA 的 RAG 技术是如何应用在我们的安全领域的。
1: 首先呢是网络安全的告警分析，呃，这个场景呢，呃，这个是呃这个任务的一个输入的示例。
1: 呃。
1: 然后网络安全告警分析这个任务，它的输入一般是一条网络安全告警和它对应的一些日志片段。
1: 然后呢，呃，RG 它的目标就是呃根据我的一个告警哦，我首先对告警进行分析，然后并生成对应的一些处置建议。
1: 然后呃这里有展示呃这里有展示我们其中一个应用的案例，我们在这里呢首先使用了 dragging 动态检索的技术来呃来让大模型来判断什么时候它需要动态的补充知识。
1: 首先呢，呃，根据这个示例的告警，大模型在呃生成漏洞原理及其缓解措呃措施之后对他后续的生成 TOKEN 呃，检测到了他的 red 得分大于了他预设的一个阈值，就可能说明他对我们企业内部的一些漏洞原因以及缓解措施不是很。
1: 确定，然后这个时候呢，就需要发起一个检索，然后通过呃在官方漏洞详情缓解建议和企业内部的 SOP 进行检索之后，呃呃，进行解锁之后，我们会我们会通过呃另一个叫生成可控的呃 react 技术呢。
1: 我们把我们解锁得来的骨钉应用步骤和 SOP 验证脚本这两个关键的文档，我们通过 cross attention 的技术，把它深入的融合到我们当前上下文的一个隐藏状态，然后这样的话呢。
1: 就确保了我们最终生成的一个处置建议，它会直接锚定在我们补充的一个权威来源里，从而避免它脱离我们结果信息，来自由的发挥内容。
1: 然后呃使用了这两个混合技术呢，呃，在我们的网络安全场景里，我们的呃处置的准确率也有了大幅提升，然后包括它的误报率也减少了14%然后这个是另一个场景的呃应用探索。
1: 呃，这个是内内容安全审核，呃，这个场景呢，它主要是呃就是我们在物流的平台，它可能有一些运单的自定义部分。
1: 它有一些呃可以让用户自由填写的部分，然后整个任务的目标就是需要用大模型来判断哦我们用户填写的部分是否包含一些呃违规的广告信息。
1: 并且生成审核结论，然后呃引用一些依据。
1: 呃，因为这里涉及到了呃需要引用依据，所以我们我们用了呃基于呃知识图谱的生成可控技术，ZCR 然后我们基于呃我们的物流安全本体，我们构建了一些呃违规广告类型、风险等级、经营条款、法律法规这样的核心子图。
1: 然后定义了他们的关联关系，然后这呃通过这些尔技术呢，我们把这些实体和关系，把它预编码为了一个前缀数。
1: 然后呃通过这个前缀数的约束，我们让大模型在解码的时候，我们仅允许它解码时沿着我们已有的子图里的关系路径生成 TOKEN 然后这里有一个呃具体的流程，呃，在我们呃示例的示例的运单备注里。
1: 呃，可能它包含了一些高度疑似广告的关键词组合，就比如说买。
1: a 货全场5折，限时促销，加微信。
1: 呃，然后呃呃首先呢，我们先用规则过滤一遍，呃，因为检测到这些关键词，我们触发了深度的审核流程。
1: 然后我们从安全的本体中，就是我们已经定义的这些组图里，我们找呃和当前这些关键词相关的一些实体和路径。
1: 然后呃在解码阶段呢，模型就受制于我们检索到的这个前缀前缀数的所有的合法后继 TOKEN 也就是说不在它电路上的候选 TOKEN 呢，我们都把它的一个呃概率分布置为负无穷。
1: 这样的话呢，我们就可以确保生成内容始终沿着我们呃预定的子图的呃预定的知识图谱的法规，然后然后生成生成合法的内容。
1: 然后这里的输出示例也可以看到呃我们的模型对于这个订单备注做了一个正确的判定。
1: 然后呃这个是第三个安全领域的应用探索的场景，叫敏感数据分类分析。
1: 然后呃这个场景的话，就是呃需要对我们输入的一个呃业务数据表它可能包括了不同敏感级别的字段，我们需要对这个用数据表的不同字段做一个多分类的任务，为它划分一个安全等级。
1: 是高中还是低，然后让模型简明的分，呃，简明的分析一下它的一个分类理由，然后因为这个任务呢，呃，我呃 RAG 准确的检索到和当前字段相关的法律法规或者是数据标准呃是非常影响整个任务的准确性的。
1: 所以呢我们在这里就使用了 Atlas 的联合训练的方法，我们首先呢用一些通用的示例问答。
1: 然后呃我们的预训练语料，一个是呃通用的法律条文和一些通用的示例问答。
1: 然后呃利用 ALAS 的技术，同时训练了解锁器和生成器。
1: 然后让模型初步的具备，它可以在我给定的一个示例问答里，可以快速准确的定位法规的一个能力。
1: 然后呃下一步就是下一个微调，因为我们呃公司内部呢，有一些隐私合规的手册和数据分类分级的标准。
1: 所以说呃下一步就是要呃根据我们呃自己的私有化数据进行进一步的微调，就比如说呃区分我们普通备注和含有个人隐私备注之间它是有细微差别的，所以说呃我们有一些自己呃内部的一些标注样本，和我们呃像像这样视力输入一样的业务数据表。然后我们通过
1: 这样的一个标注样本，然后对模型进行了呃进一步的微调。
1: 然后我们可以看一下。
1: 视力输出，然后经过 Alex 的两轮呃预训练和微调之后呢，然后大模型它可以准确的识别到不同的呃一张用户数据表中不同的字段的敏感级别。
1: 然后它呃较传统我们使用的规则模型呢，准确率可以呃获得大的提升，而且因为它呃给出了呃它的一个判别理由，也使人工的负荷量大大的减少。
1: 然后这是演讲最后，我给大家呃大概回顾一下今天分享的内容。
1: 呃，首先呢，呃，首先呢，哦，我分享了三个不同的先进的 Rag 框架。
1: 就是实时检索，然后实时检索呢，它是呃动态的，让大模型来判断它什么时候有发，呃，有信息接口，什么时候需要通过呃通过一些算法来补，呃，向外部知识库发起查询，补充知识。
1: 然后这里涉及到两个技术框架，一个是 dragging 一个是 Blair 然后他们的一个核心的策略就是通过模型的一些固有的一些输出，就比如说呃输出的 TOKEN 的概率分布。
1: 和自注意力权重来判断什么时候需要出发检索。
1: 然后下一个技术呢是可控生成，呃呃，就是在我给定的一些呃呃检索知识的范围内，我呃如何让生成器在我给定的范围内呃进行生成？
1: 然后呃这里有介绍到两种不同不同的呃不同的策略，一个是架构上，呃，通过在传统的 Transformer 结构中加入一些 cross attentions 呃，可以让呃可以让我检索到的信息和我当前生成的上下文进行一个深入的融合。
1: 所以呃这样的话呢，让呃解码的那个信息呃间接的偏向了我检索的一个来源，然后另一个就是我通过维护一个呃词呃词表或者是图谱，然后把它预编译为一个前缀树，然后让模型在解码的时候。
1: 然后强制的让它偏向这些图谱或者是词表里呃约束的路径，然后从而实现一个零幻觉的效果。
1: 然后最后一个技术就是检索生成的联合训练，我通过呃让检索生成共享同一个损失函数，然后实现了呃模块串联到一个一体化的 RG 然后联合训练的损失设计是一个是对比损失。
1: 呃，通过通过呃注意力蒸馏，或者是呃简，呃，生成器的一些呃输出的自然分布，我们来呃通过这样的一个监督监督信号来呃影响检索器的呃检索参数，然后这样的话呢，是是检索和生成的目标需求可以保持高度的对齐。
1: 然后最后呢，我们看了三个不同的呃安全场景。
1: 然后呃呃也大概看了一下他们是如何在职业场景中进行训练的，然后他的呃准确率和无论是检测率、漏判率，还是呃最终的一个呃节省人工成本的呃时长都获得了很大的提升。
1: 好，然后这就是我今天分享的内容。
1: 呃，如果大家有什么问题的话呢，现在欢迎大家提问。
2: 老师你好，啊，我想问一下刚才第一个信息检索的然后呃这个我有点疑惑，是是，啊，也可以。
2: 然后我们是先做召回，然后召回之后给大模型做生成，然后当大模型发现啊它有疑惑，然后就是自信度比较低的时候，才去发起第二轮的召回嘛。
2: 还是说一开始就不先召回了，直接让让我去生成。
1: 啊，是这样的。
1: 啊，它不同的不同的框架，它有不同的策略。
1: 像是 Dragon 的话，它是在生成的时候，我呃我之前有介绍到这个 run 模块，它是在我呃生成每个 TOKEN 的时候，它都同时会计算这个呃得分，run 的得分，然后我因为我有个预设的阈值。
1: 我会实时的将这个 Ryan 的得分和我的预设的阈值进行比较，如果当下生成的这个 TOKEN 它的得分低，呃，高于了我这个阈值，就说明它它是不确定的，然后此时就触发检索。
1: 这是一个，然后另一个呃叫 Flair 的论文呢，它可能是呃它不是说是实时的检测我每个 TOKEN 的概率，而是它在呃它它的呃生成的力度是逐句逐句生成，所以它在生成到呃下一个句子的时候。
1: 它会评判每一个句子里所有 TOKEN 的一个执行度，然后如果它这个句子里存在低于我预设的一个阈值的一个 TOKEN 这个时候我就出发检索，补充知识，然后呃可能会改写我下一个生成的句子。
2: 啊，OK 大概是这样。
2: 然后我我们如果是检测到需要检索，那我检索完了之后，然后继续生成的过程中，我们是呃直接把我们检索到的内容去替换原来的上下文，然后直接让他给您到最后一个生成的功能的时候继续生成是吧？
1: 啊，对对对，呃，现在通用的方法是还是通过提示词，把呃把检索到的知识注入，因为呃模型它有 self attention 机制，所以它大概知道自己前文在写什么，所以说你把知识注入，呃，通过提示词注入之后。
1: 它可以从呃从自己截断的地方继续生成。
2: OK 所以用户感知到的是，停了一下，他几秒钟，然后他继续。
2: 对对对。
2: 好，谢谢老师。
2: 都都可以都可以。
3: 老师你好，那我有两个问题，一个是刚刚其实嗯那位那位那位嗯那位同学已经问了，但是我我我现在还想呃沿着他那个问题再追问一下，就刚刚我们提到的几个框架，其实哦。
3: 我我我个人的理解好像是要去做一些底层的模型改造，而不是说我，你拿一个传统的大模型，我就能知道说我我我可以让这个模型说去判断一些自信度之类的。
1: 啊，没有，现呃模型的呃固有的输出里，它是包含生成的概率和自注意力权重的。
1: 呃，但是可能这跟大家平时调用的那种 API 不太一样，啊，对吧？
1: 如，但是呢，如果是使用的是呃比如说开源模型，你部署到自己本地环境的话，你是很容易获取到这个概率的。
3: ok 啊，这是我们用传统开源的模型，或者说嗯对，我们平时没没没没注意，反正就是我们用这个框架，其实我们其实是可以利用基于这个框架，然后基于我们传统的，比如说开源也好。
3: 或者是说 API 也好，其实是能实现刚刚你讲的，比如说实时搜索的这种能力，对吧？
3: 不需要我自己去做模型的改造是吧？
1: 啊，这是不需要的。
1: 哦，这个 Dragon 包括那里它是可以适配任何的一个生成器。
3: 好的，谢谢老师。
3: 然后第二个问题是说，因为我们传统的呃编搜索的还有边检测其实会带来一个就是一个，我我感觉是延时应该会比较重，就就因为你还得去判断说那个，我检索的东西可能要检索多次，对吧？
1: 哦，这个这个没有，因为呃你可以看到这里一个是呃生成的概率，你你有生成的概率，你才有可能生成下一个 TOKEN 对吧？
1: 嗯嗯。
1: 所以这个这个是你在生成 TOKEN 的时候，它就实时有的是这个数据，包括这个自注意力权重，然后最终呢我做的只是一个呃相乘的操作，所以这个计算的速度是完全是线性且可控的，它没有任何的延时。
1: ok。
3: 谢谢老师。
3: 好。
3: 哎，老师你好。
3: 呃，我有两个问题想问一下，就是呃您刚提到的那个有一个那个 GCR 这个流程，对吧？
3: 就是其中关于的那个知识突破的那个，基于知识突破做一个前缀数的一个修正。
3: 我特别想问一下，就是这个知识突破应该怎么去构建呢？
3: 就现在有很多的框架，呃，我想问的，我不是说框架啊，就是我这边现在是因为我们这边有现有一个业务，就是我们自己在做的，就是一个智能温数的一个业务，呃，温数的话，它需要有很多的数据表。
3: 这个表可能是有几千张，然后呢其实我们已经在它的大模型的 prompt 里面告诉了它，你需要去怎么去找这些表。
3: 但是呢，他始终是不按照我的 prompt 去走，他总是会有一些自己的幻觉。
3: 所以说我们希望就是通过您刚说的这种方式去强制执行他的这个思维过程。
3: 嗯。
3: 所以说就基于我们现在这个业务场景，能不能有一个泛化的解决方案，让这，让我这个图谱能根据任何的一个呃业务，去把这个构建出来。
1: 呃，首先你们的图谱是已经建立好，还是没有建立好？
3: 我们的图谱是基于我们这个知识库的一个 IG 的一个图谱。
3: 对。
1: 哦，所以我们没有构建您刚说的那个，你刚说这个图谱是不是跟我这个，这个是任意一个知识图谱，但是这个机器人它能工作的前提就是你要有一个呃定义好的，完全可以工作的，而且这个实体是呃实体关系。
1: 之间是完全有意义的一个图谱，就是它它的前提就是你得有一个你得有一个比较好。
3: 就就是我的意思是您这个图谱它是一个思维链的一个图谱，还是说实际上就是我刚用，它可以是任意一种形式，图谱只是其中一个。
1: 然后你呃你说的那个思维链，因为它也是一个链式的，它是有一个合法的后后期投肯的，所以说呃我觉得只要改造一下这个计算算法也可以使用，因为呃它也是一环扣一环。
3: 就是我现在业务上用于 ie 的那个同步，上面是包含了真实的业务数据的嘛，对吧？
3: 就是您说是基于那个同步进行一个改造。
3: 呃。
3: 就是说，因为我没太听懂，因为就是我那个，包含，比如说我现在这个业务场景上，就是有很多真实的数据嘛，那个数据跟这个，跟您说的这
